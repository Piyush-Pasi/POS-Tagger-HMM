{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HMM-Viterbi-Trigram-Model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7c8XWSwb7eD"
      },
      "source": [
        "## Loading Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkS9ALQg3nCR"
      },
      "source": [
        "# Importing libraries\n",
        "import nltk\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import string\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5uetwNk4kZ8"
      },
      "source": [
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqZRbCSRpaZ1"
      },
      "source": [
        "# Train and Test Data \n",
        "#### Note : If custom train and test set are used please make sure the data type and format is same, and you can skip these cells (But run other cells with functions) or can assign your train,test set to the ones mentioned below\n",
        "\n",
        "### train_set, test_set : List[ List [ tuple(word,tag) ] ]\n",
        "\n",
        "#### Run HMM_Viterbi_Train() and HMM_Viterbi_Test() with your custom input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5xtU9BL4aHD"
      },
      "source": [
        "nltk_data = list(nltk.corpus.brown.tagged_sents(tagset='universal'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9gIiJCQ4dgJ"
      },
      "source": [
        "train_set,test_set =train_test_split(nltk_data,train_size=0.80,test_size=0.20,random_state = 101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD8l1xrh4uoA"
      },
      "source": [
        "print(len(test_set))\n",
        "print(len(train_set))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl5qodyJcXlN"
      },
      "source": [
        "## Unigram Probability and Tag Counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK0-Pl7N4wzE"
      },
      "source": [
        "allWords = {}\n",
        "allTags = {}\n",
        "def tag_and_words(train_set):\n",
        "  global allWords\n",
        "  global allTags\n",
        "  allWords = {}\n",
        "  allTags = {}\n",
        "  allWords = {word for sent in train_set for word,_ in sent}\n",
        "  allTags = sorted({tag for sent in train_set for _,tag in sent})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR_1mOzoNhuU"
      },
      "source": [
        "def generate_Unigram_Prob(train_set):\n",
        "  tagCounts ={ tag:0 for tag in allTags}\n",
        "  for sent in train_set:\n",
        "    for _,tag in sent:\n",
        "      tagCounts[tag] += 1\n",
        "  totalTagCount = sum(tagCounts.values())\n",
        "  tagUnigramProb = {}\n",
        "  if totalTagCount != 0:\n",
        "    tagUnigramProb = { tag: (val/totalTagCount) for tag,val in zip(tagCounts.keys(), tagCounts.values()) }\n",
        "  return tagUnigramProb, tagCounts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiFbJjRARTDo"
      },
      "source": [
        "## Generating Emission Probability\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKSoibl_RXFy"
      },
      "source": [
        "def generate_Emission_Prob_Table(train_set):\n",
        "  emissionProbTable = pd.DataFrame(0.0, columns=allTags, index=allWords)\n",
        "  for sent in train_set:\n",
        "    for word,tag in sent:\n",
        "      emissionProbTable.loc[ word, tag] += 1\n",
        "  for tag in allTags:\n",
        "    total = sum(emissionProbTable[tag])\n",
        "    if total != 0:\n",
        "      emissionProbTable[tag] = emissionProbTable[tag].div(total)\n",
        "\n",
        "  return emissionProbTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-LlrUTMPuFz"
      },
      "source": [
        "## Generating BiGram Transition Probability\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bswjsr2SPzpt"
      },
      "source": [
        "def myBigrams(sent):\n",
        "  bigrams = []\n",
        "  for i in range(len(sent)-1):\n",
        "    bigrams.append((sent[i], sent[i+1]))\n",
        "  return bigrams\n",
        "\n",
        "def generate_Bigram_Transition_Table(train_set):\n",
        "  tagBigramProb = pd.DataFrame(0.0,columns=allTags, index=allTags)\n",
        "  for sent in train_set:\n",
        "    bi = myBigrams(sent)\n",
        "    for b1,b2 in bi:\n",
        "      tagBigramProb.loc[ b1[1], b2[1] ] += 1\n",
        "  biGramCount = tagBigramProb.copy()\n",
        "\n",
        "  for tag in allTags:\n",
        "    total = sum(tagBigramProb.loc[tag, :])\n",
        "    if total != 0:\n",
        "      tagBigramProb.loc[tag, :] = tagBigramProb.loc[tag, :].div(total) \n",
        "  \n",
        "  return tagBigramProb, biGramCount\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v64hSrFecZcm"
      },
      "source": [
        "## Loading Tag Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoCJZc_H0Yk-"
      },
      "source": [
        "with open('./pronouns.pkl','rb') as file:\n",
        "  pronouns = pickle.load( file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVPqWYyYcfZ2"
      },
      "source": [
        "## Generating Trigram Transition Probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Tm1SgT6lWQ"
      },
      "source": [
        "def myTrigrams(sent):\n",
        "  trigrams = []\n",
        "  for i in range(len(sent)-2):\n",
        "    trigrams.append((sent[i], sent[i+1], sent[i+2]))\n",
        "  return trigrams\n",
        "\n",
        "def generate_Trigram_Transition_Table(train_set):\n",
        "  trigramGiven = sorted({ \"({},{})\".format(t1,t2) for t1 in allTags for t2 in allTags})\n",
        "  tagTrigramProb = pd.DataFrame(0.0,columns=allTags, index=trigramGiven)\n",
        "  for sent in train_set:\n",
        "    tri = myTrigrams(sent)\n",
        "    for t1,t2,t3 in tri:\n",
        "      tagTrigramProb.loc[ \"({},{})\".format(t1[1], t2[1]) , t3[1] ] += 1\n",
        "\n",
        "  trigramCount = tagTrigramProb.copy()\n",
        "  \n",
        "  for tag in trigramGiven:\n",
        "    total = sum(tagTrigramProb.loc[tag, :])\n",
        "    if total != 0:\n",
        "      tagTrigramProb.loc[tag, :] = tagTrigramProb.loc[tag, :].div(total)\n",
        "\n",
        "  return tagTrigramProb, trigramCount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4AExFVVnQ_T"
      },
      "source": [
        "'''for tag in sorted({ \"({},{})\".format(t1,t2) for t1 in allTags for t2 in allTags}):\n",
        "  total = sum(x[0].loc[tag, :])\n",
        "  print(total)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFLqtC6-UYfV"
      },
      "source": [
        "## Trigram Transition Probabilities with deleted interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMV9Eqlgdm4W"
      },
      "source": [
        "def deleted_interpolation(tagCounts, biGramCount, trigramCount):\n",
        "  l1 = l2 = l3 = 0\n",
        "  triplets = [(a,b,c) for a in allTags for b in allTags for c in allTags]\n",
        "  for a,b,c in triplets:\n",
        "    triCount = trigramCount.loc[\"({},{})\".format(a,b), c]\n",
        "    if triCount > 0:\n",
        "      try: \n",
        "        k1 = (triCount-1)/(biGramCount.loc[a, b] - 1)\n",
        "      except :\n",
        "        k1 = 0.0\n",
        "      try:\n",
        "        k2 = (biGramCount.loc[a, b] - 1)/( tagCounts[a] - 1)\n",
        "      except :\n",
        "        k2 = 0.0\n",
        "      try:\n",
        "        k3 = ( tagCounts[a] - 1)/(sum(tagCounts.values()) -1)\n",
        "      except :\n",
        "        k3 = 0.0\n",
        "      #print(k1,k2,k3)\n",
        "      k = np.argmax([k1, k2, k3])\n",
        "      if k==0:\n",
        "        l1 += triCount\n",
        "      if k==1:\n",
        "        l2 += triCount\n",
        "      if k==2:\n",
        "        l3 += triCount\n",
        "  wts = [l1, l2, l3]\n",
        "  return [l/(sum(wts)) for l in wts]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4U3mKyAUjD8"
      },
      "source": [
        "def generate_Trigram_Prob_Table_D(tagUnigramProb, tagBigramProb, tagTrigramProb, lambdas):\n",
        "  trigramGiven = sorted({ \"({},{})\".format(t1,t2) for t1 in allTags for t2 in allTags})\n",
        "  tagTrigramProb_D = pd.DataFrame(0.0,columns=allTags, index=trigramGiven)\n",
        "\n",
        "  triplets = [(a,b,c) for a in allTags for b in allTags for c in allTags]\n",
        "  for a,b,c in triplets:\n",
        "    r = \"({},{})\".format(a,b)\n",
        "    tagTrigramProb_D.loc[ r, c] += (\n",
        "        lambdas[0]*tagTrigramProb.loc[ r, c] +\n",
        "        lambdas[1]*tagBigramProb.loc[ b, c] +\n",
        "        lambdas[2]*tagUnigramProb[c]                               \n",
        "    )\n",
        "                                \n",
        "  return tagTrigramProb_D\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMadsWNLfy4Y"
      },
      "source": [
        "## Viterbti Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2CeXjxax9Uq"
      },
      "source": [
        "def get_word(sent,k):\n",
        "        if k < 0:\n",
        "            return '.'\n",
        "        else:\n",
        "            return sent[k]\n",
        "\n",
        "def get_tags(k):\n",
        "        if k == -1:\n",
        "            return set(['.'])\n",
        "        if k == 0:\n",
        "            return set(['.'])\n",
        "        else:\n",
        "            return allTags\n",
        "\n",
        "def get_transition(transitionProbTable, w, u, v):\n",
        "  if w=='':\n",
        "    w = '.'\n",
        "  if u=='':\n",
        "    u = '.'\n",
        "  if v=='':\n",
        "    v = '.'\n",
        "  r = \"({},{})\".format(w, u)\n",
        "  return transitionProbTable.loc[ r, v]\n",
        "\n",
        "def get_emission(emissionProbTable, word, tag, unseenWord):\n",
        "  if unseenWord:\n",
        "    if findTag_UnseenWords(word) == tag:\n",
        "      return 1\n",
        "    else :\n",
        "      return 0\n",
        "  else:\n",
        "    return emissionProbTable.loc[word, tag]\n",
        "\n",
        "def get_V(V,n,u,v):\n",
        "  try:\n",
        "    return V[n,u,v]\n",
        "  except:\n",
        "    return 0\n",
        "\n",
        "def findTag_UnseenWords(word):\n",
        "    if not re.search(r'\\w', word):\n",
        "        return '.'\n",
        "    elif word.lower() in pronouns:\n",
        "        return 'PRON'\n",
        "    elif re.search(r'\\d', word):\n",
        "        return 'NUM'\n",
        "    elif re.search(r'(ion\\b|ian\\b|ty\\b|ics\\b|ment\\b|ence\\b|ance\\b|ness\\b|ist\\b|ism\\b)',word):\n",
        "        return 'NOUN'\n",
        "    elif word.istitle():\n",
        "        return 'NOUN'\n",
        "    elif re.search(r'(ate\\b|fy\\b|ize\\b|\\ben|\\bem|ing\\b|ed\\b|es\\b)', word):\n",
        "        return 'VERB'\n",
        "    elif re.search(r'(\\bun|\\bin|ble\\b|ry\\b|ish\\b|ious\\b|ical\\b|\\bnon|ful\\b|less\\b)',word):\n",
        "        return 'ADJ'\n",
        "    elif re.search(r'(\\*T?\\*?-[0-9]+$)', word):\n",
        "        return 'X'\n",
        "    else:\n",
        "        return 'NOUN'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQaTWs42sRh8"
      },
      "source": [
        "def viterbi(sent, transitionProbTable, emissionProbTable):\n",
        "        V = {}\n",
        "        path = {}\n",
        "        \n",
        "        V[0,'.','.'] = 1\n",
        "        path['.','.'] = []\n",
        "        \n",
        "        \n",
        "        for k in range(1,len(sent)+1):\n",
        "            temp_path = {}\n",
        "            word = get_word(sent,k-1)\n",
        "\n",
        "            unseenWord = False\n",
        "            if word not in allWords:\n",
        "              if word.lower() not in allWords:\n",
        "                unseenWord = True\n",
        "              else :\n",
        "                word = word.lower()\n",
        "           \n",
        "            for u in get_tags(k-1):\n",
        "                  \n",
        "                  for v in get_tags(k):\n",
        "                      V[k,u,v],prev_w = max([( get_V(V,k-1,w,u) * get_transition(transitionProbTable,w,u,v) * get_emission(emissionProbTable,word,v, unseenWord),w) for w in get_tags(k-2)])\n",
        "                      temp_path[u,v] = path[prev_w,u] + [v]\n",
        "                      \n",
        "            path = temp_path\n",
        "\n",
        "\n",
        "        prob,umax,vmax = max([(get_V(V,len(sent),u,v) * get_transition(transitionProbTable,u,v,'.'),u,v) for u in allTags for v in allTags])\n",
        "        \n",
        "        return path[umax,vmax]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLjyHee4f6c6"
      },
      "source": [
        "## Training HMM POS Tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBOZ9VbtYFFx"
      },
      "source": [
        "def HMM_Viterbi_Train(train_set):\n",
        "  print(\"# Generating Transition & Emission Probability Table...\")\n",
        "  tag_and_words(train_set)\n",
        "  tagUnigramProb, tagCounts = generate_Unigram_Prob(train_set)\n",
        "  #print(\"Unigram Transition Probability\",tagUnigramProb)\n",
        "  print(\"# Calculating Bigram Transition Prob...\")\n",
        "  tagBigramProb, biGramCount = generate_Bigram_Transition_Table(train_set)\n",
        "  #print(tagBigramProb)\n",
        "  print(\"# Calculating Trigram Transition Prob...\")\n",
        "  tagTrigramProb, trigramCount = generate_Trigram_Transition_Table(train_set)\n",
        "  #print(tagTrigramProb)\n",
        "  lambdas = deleted_interpolation(tagCounts, biGramCount, trigramCount)\n",
        "  print(\"# Calculating Trigram Transition Prob Deleted Interpolation...\")\n",
        "  transition_d = generate_Trigram_Prob_Table_D(tagUnigramProb, tagBigramProb, tagTrigramProb, lambdas)\n",
        "  #print(transition_d)\n",
        "  print(\"# Calculating Emission Prob...\")\n",
        "  emission = generate_Emission_Prob_Table(train_set)\n",
        "  #print(emission.head(15))\n",
        "  return emission, tagBigramProb, tagTrigramProb, transition_d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NQQTVIUhReA"
      },
      "source": [
        "## Testing HMM POS Tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7nwBB8j0nkK"
      },
      "source": [
        "def HMM_Viterbi_Test(test_set, transitionProbTable, emissionProbTable):\n",
        "\n",
        "  output_tags = []\n",
        "  input_word_tags = []\n",
        "  counter = 0\n",
        "  for sent in test_set:\n",
        "    counter += 1\n",
        "    print(counter, end=\" \")\n",
        "    if not (counter%40):\n",
        "      print(\"\\n\")\n",
        "    sent_words = [ word for word,_ in sent]\n",
        "    input_word_tags += [tup for tup in sent]\n",
        "    output_tags += viterbi(sent_words, transitionProbTable, emissionProbTable)\n",
        "    \n",
        "    \n",
        "  return input_word_tags, output_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWcAyND0qNzi"
      },
      "source": [
        "## Calling Train & Test Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP_hUaKNgukw"
      },
      "source": [
        "emission, bi_Transition, tri_transition, tri_d_transition = HMM_Viterbi_Train(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCKTZF1xz9U9"
      },
      "source": [
        "emission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1VNjpJozuNq"
      },
      "source": [
        "bi_Transition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTErtFyv1DOY"
      },
      "source": [
        "tri_transition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7TwfqLh1FeM"
      },
      "source": [
        "tri_d_transition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5shhkCz-lj1T"
      },
      "source": [
        "## Output for test data set :\n",
        "# Caution \\#: for large number of sentences longer waiting time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjkZ1XpMp8Bt"
      },
      "source": [
        "input_word_tag, output_tags = HMM_Viterbi_Test(test_set, tri_d_transition, emission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IstQF99NwhD"
      },
      "source": [
        "print(\"Accuracy: {}\".format(len([1 for i in range(len(output_tags)) if input_word_tag[i][1]==output_tags[i]])/len(output_tags) ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiIWsIgKmrdl"
      },
      "source": [
        "# Custom Sentence Testing\n",
        "### For your own sentence prediction run below 2 cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eopPOMS6lRXq"
      },
      "source": [
        "inp_text = input(\"Enter your sentence : \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71K9Y3hfCut-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTAQxJ-aVmAA"
      },
      "source": [
        "viterbi( inp_text.split(\" \") , tri_d_transition, emission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAgiENhonY_6"
      },
      "source": [
        "# Analysis metrics and Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0eCQILFQUC9"
      },
      "source": [
        "actual_tags = [t for _,t in input_word_tag]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isAuGVrqQaFu"
      },
      "source": [
        "predicted_tags = output_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_60Taz4A-_G"
      },
      "source": [
        "print(metrics.classification_report(actual_tags, predicted_tags,labels=allTags))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQLb62ZkA220"
      },
      "source": [
        "cm = metrics.confusion_matrix(actual_tags, predicted_tags,labels=allTags)\n",
        "\n",
        "df_cm = pd.DataFrame(cm, index = allTags,\n",
        "                  columns = allTags)\n",
        "fig=plt.figure(figsize = (10,7))\n",
        "\n",
        "\n",
        "cmap = sns.cm.rocket_r\n",
        "ax=sns.heatmap(df_cm, annot=True, yticklabels=allTags , cmap=cmap, fmt='d')\n",
        "ax.set_xlabel('Predicted '+r'$\\longrightarrow$')\n",
        "ax.set_ylabel('Actual '+r'$\\longrightarrow$')\n",
        "plt.yticks(rotation=0) \n",
        "ax.set_title('Confusion Matrix of HMM-Viterbi Trigram Model')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGKq4iTwBBuY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}